{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function created!\n"
     ]
    }
   ],
   "source": [
    "import re # import \"re\" function\n",
    "\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    '''\n",
    "    A caret located in a bracket means ‘not.’ \n",
    "    If remove_digits parameter is True, \"^a-zA-Z0-9\\s\" matches any characters other than \n",
    "    alphabets ([a-zA-Z]) or digits ([0-9]), followed by a white space ([\\s]).\n",
    "    If 'remove_digits' parameter is False, the the function will remove numbers as well. \n",
    "    '''\n",
    "    pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "print(\"Function created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well this was fun What do you think '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing Special Characters\n",
    "remove_special_characters(\"Well this was fun! What do you think? 123#@\", \n",
    "                          remove_digits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well this was fun What do you think 123'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing Special Characters\n",
    "remove_special_characters(\"Well this was fun! What do you think? 123#@\", \n",
    "                          remove_digits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages imported!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "#Removing Stopwords\n",
    "import nltk # import nltk library\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "print(\"Packages imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function created!\n"
     ]
    }
   ],
   "source": [
    "#create the remove_stopwords function\n",
    "\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no') # we will not remove 'no' from texts\n",
    "stopword_list.remove('not') # we will not reomve 'not' from texts\n",
    "\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    # First, tokenize the text\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    # remove whitespaces in each token\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    # if \"is_lower_case\" parameter is True, \n",
    "    # we will not remove stopwords that have any upper case letter\n",
    "    if is_lower_case: \n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    # If \"is_lower_case\" parameter is False, \n",
    "    # we will remove any stopwords no matter whether they are in uppercase or not\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "print(\"Function created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', , StopWords , computer not'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#execution 1\n",
    "remove_stopwords(\"The, and, if are StopWords, computer is not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The , , StopWords , computer not'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#execution 2\n",
    "remove_stopwords(\"The, and, if are StopWords, computer is not\", is_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nConsider the below product reviews:\\n\\nThe product is really very good. – POSITIVE\\nThe product seems to be good. – POSITIVE\\nGood product. I really liked it. – POSITIVE\\nThe product is not good. – NEGATIVE\\nI didn’t like the product. – NEGATIVE\\n\\nEach numbered reviewhas the review text on the left and the label on the right. \\nA product review will be labeled either 'POSITIVE' or 'NEGATIVE'.\\n\\nRemove stopwords in each review using the code provided earlier in the module. \\nThen, observe what happens to the review comments. \\nFinally, critically argue whether stopwords removal improves model performance in any context.\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# excercise\n",
    "\n",
    "'''\n",
    "Consider the below product reviews:\n",
    "\n",
    "The product is really very good. – POSITIVE\n",
    "The product seems to be good. – POSITIVE\n",
    "Good product. I really liked it. – POSITIVE\n",
    "The product is not good. – NEGATIVE\n",
    "I didn’t like the product. – NEGATIVE\n",
    "\n",
    "Each numbered reviewhas the review text on the left and the label on the right. \n",
    "A product review will be labeled either 'POSITIVE' or 'NEGATIVE'.\n",
    "\n",
    "Remove stopwords in each review using the code provided earlier in the module. \n",
    "Then, observe what happens to the review comments. \n",
    "Finally, critically argue whether stopwords removal improves model performance in any context.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product really good POSITIVE\n",
      "product seems good POSITIVE\n",
      "Good product really liked POSITIVE\n",
      "product not good NEGATIVE\n",
      "didnt like product NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "sentence1=remove_stopwords(remove_special_characters(\"The product is really very good. – POSITIVE\", remove_digits=False))\n",
    "sentence2=remove_stopwords(remove_special_characters(\"The product seems to be good. – POSITIVE\", remove_digits=False))\n",
    "sentence3=remove_stopwords(remove_special_characters(\"Good product. I really liked it. – POSITIVE\", remove_digits=False))\n",
    "sentence4=remove_stopwords(remove_special_characters(\"The product is not good. – NEGATIVE\", remove_digits=False))\n",
    "sentence5=remove_stopwords(remove_special_characters(\"I didn’t like the product. – NEGATIVE\", remove_digits=False))\n",
    "\n",
    "print(sentence1)\n",
    "print(sentence2)\n",
    "print(sentence3)\n",
    "print(sentence4)\n",
    "print(sentence5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
