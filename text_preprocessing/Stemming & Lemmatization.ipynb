{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function created!\n",
      "Packages imported!\n",
      "Function created!\n",
      "Function created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re # import \"re\" function\n",
    "\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    '''\n",
    "    A caret located in a bracket means ‘not.’ \n",
    "    If remove_digits parameter is True, \"^a-zA-Z0-9\\s\" matches any characters other than \n",
    "    alphabets ([a-zA-Z]) or digits ([0-9]), followed by a white space ([\\s]).\n",
    "    If 'remove_digits' parameter is False, the the function will remove numbers as well. \n",
    "    '''\n",
    "    pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "print(\"Function created!\")\n",
    "\n",
    "\n",
    "import nltk # import nltk library\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "print(\"Packages imported!\")\n",
    "\n",
    "\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no') # we will not remove 'no' from texts\n",
    "stopword_list.remove('not') # we will not reomve 'not' from texts\n",
    "\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    # First, tokenize the text\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    # remove whitespaces in each token\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    # if \"is_lower_case\" parameter is True, \n",
    "    # we will not remove stopwords that have any upper case letter\n",
    "    if is_lower_case: \n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    # If \"is_lower_case\" parameter is False, \n",
    "    # we will remove any stopwords no matter whether they are in uppercase or not\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "print(\"Function created!\")\n",
    "\n",
    "\n",
    "#create the simple_stemmer function\n",
    "def simple_stemmer(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    # split the text into individual word and return a list of words\n",
    "    # the 'ps' function stems each word, and .join() function joins the stemmed words with whitespace.\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()]) \n",
    "    return text\n",
    "\n",
    "print(\"Function created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My system keep crash hi crash yesterday, our crash daili'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_stemmer(\"My system keeps crashing his crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# create the lemmatize_text function\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    s = \" \" # create an empty string that later will contain lemmatized words,\n",
    "    t_l = [] # create an empty list\n",
    "    t_w = nltk.word_tokenize(text) # tokenize the text\n",
    "    # assign the list of tokenized words into t_w.\n",
    "    for w in t_w:\n",
    "        # “pos” is a part of speech parameter and “v” means verbs. \n",
    "        # We will lemmatize verbs only. \n",
    "        l_w = wordnet_lemmatizer.lemmatize(w, pos=\"v\")\n",
    "        # append l_w into the list t_l\n",
    "        t_l.append(l_w)\n",
    "    # joint the tokens to make a complete sentence\n",
    "    text = s.join(t_l)\n",
    "    return text\n",
    "\n",
    "print(\"Function created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My system keep crash ! his be crash yesterday , ours crash daily'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_text(\"My system keeps crashing! his was crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "measure serum lipid profile together plasma fibrinogen serum lipoproteina Lpa glucose bilirubin albumin level 491 patients 310 men refer management primary dyslipidemia variables show predict vascular events patients not take lipidlowering drug hypertension present 156 317 hypertensive patients 52 33 not receive treatment control blood pressure Lipidhostile antihypertensive drug associate significantly higher fibrinogen concentration compare untreated hypertensives take lipidneutrallipidfriendly drug median value 383 353 336 mgdL respectively P 01 Lipidneutrallipidfriendly antihypertensive drug associate lower Lpa level compare untreated hypertensives median value 22 45 mgdL respectively P 05 serum bilirubin level significantly lower untreated hypertensives compare normotensives treat hypertensives no significant differences lipids glucose albumin among group hypertensives normotensives influence antihypertensive drug additional cardiovascular risk factor consider select medication reduce blood pressure\n"
     ]
    }
   ],
   "source": [
    "text = \"We measured the serum lipid profile, together with plasma fibrinogen and serum lipoprotein(a) (Lp[a]), glucose, bilirubin, and albumin levels in 491 patients (310 men) who were referred for the management of primary dyslipidemia. All these variables have been shown to predict vascular events. The patients were not taking lipid-lowering drugs; hypertension was present in 156 (31.7%) of them. Of the hypertensive patients, 52 (33%) were not receiving any treatment to control their blood pressure. Lipid-hostile antihypertensive drugs were associated with a significantly higher fibrinogen concentration when compared with untreated hypertensives or those taking lipid-neutral/lipid-friendly drugs (median values: 383, 353, and 336 mg/dL, respectively; P < .01). Lipid-neutral/lipid-friendly antihypertensive drugs were associated with lower Lp(a) levels when compared with untreated hypertensives (median values: 22 and 45 mg/dL, respectively; P < .05). The serum bilirubin level was significantly lower in the untreated hypertensives when compared with normotensives or the treated hypertensives. There were no significant differences in lipids, glucose, or albumin among the groups of hypertensives or normotensives. The influence of antihypertensive drugs on additional cardiovascular risk factors should be considered when selecting medication to reduce blood pressure.\"\n",
    "rm_sc=remove_special_characters(text)\n",
    "rm_sw=remove_stopwords(rm_sc)\n",
    "final_text=lemmatize_text(rm_sw)\n",
    "\n",
    "print(final_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
